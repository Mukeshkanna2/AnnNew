{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "u1e4enEHznNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50871cac-d344-4f20-82ff-27fcc3a92b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'batch_size': 64, 'epoch': 200, 'learning_rate': 0.001, 'hidden_layer1_neurons': 32, 'hidden_layer2_neurons': 16}\n",
            "Best accuracy:  0.7369791666666666\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the sigmoid and tanh activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Load the dataset\n",
        "dataset =pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "# Preprocess the data\n",
        "X = dataset.drop('Outcome', axis=1).values\n",
        "y = dataset['Outcome'].values.reshape(-1, 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_idx = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_idx], y[:train_idx]\n",
        "X_test, y_test = X[train_idx:], y[train_idx:]\n",
        "\n",
        "# Scale the data\n",
        "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
        "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n",
        "\n",
        "# Initialize hyperparameters\n",
        "batch_sizes = [16, 32, 64]\n",
        "epochs = [50, 100, 200]\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "hidden_layer1_neurons = [8, 16, 32]\n",
        "hidden_layer2_neurons = [8, 16, 32]\n",
        "\n",
        "# Define the neural network architecture\n",
        "input_layer_size = X.shape[1]\n",
        "output_layer_size = y.shape[1]\n",
        "\n",
        "# Train the model with different hyperparameter combinations\n",
        "best_accuracy = 0\n",
        "for batch_size in batch_sizes:\n",
        "    for epoch in epochs:\n",
        "        for learning_rate in learning_rates:\n",
        "            for h1_neurons in hidden_layer1_neurons:\n",
        "                for h2_neurons in hidden_layer2_neurons:\n",
        "                    np.random.seed(1)\n",
        "                    # Initialize weights\n",
        "                    w1 = np.random.randn(input_layer_size, h1_neurons)\n",
        "                    b1 = np.zeros((1, h1_neurons))\n",
        "                    w2 = np.random.randn(h1_neurons, h2_neurons)\n",
        "                    b2 = np.zeros((1, h2_neurons))\n",
        "                    w3 = np.random.randn(h2_neurons, output_layer_size)\n",
        "                    b3 = np.zeros((1, output_layer_size))\n",
        "                    # Train the model\n",
        "                    for i in range(epoch):\n",
        "                        for j in range(0, X.shape[0], batch_size):\n",
        "                            # Forward propagation\n",
        "                            z1 = np.dot(X[j:j+batch_size], w1) + b1\n",
        "                            a1 = tanh(z1)\n",
        "                            z2 = np.dot(a1, w2) + b2\n",
        "                            a2 = tanh(z2)\n",
        "                            z3 = np.dot(a2, w3) + b3\n",
        "                            y_hat = sigmoid(z3)\n",
        "                            # Backward propagation\n",
        "                            error = y_hat - y[j:j+batch_size]\n",
        "                            d3 = error * y_hat * (1 - y_hat)\n",
        "                            d2 = np.dot(d3, w3.T) * (1 - a2**2)\n",
        "                            d1 = np.dot(d2, w2.T) * (1 - a1**2)\n",
        "                            # Update weights\n",
        "                            w3 -= learning_rate * np.dot(a2.T, d3)\n",
        "                            b3 -= learning_rate * np.sum(d3, axis=0, keepdims=True)\n",
        "                            w2 -= learning_rate * np.dot(a1.T, d2)\n",
        "                            b2 -= learning_rate * np.sum(d2, axis=0)\n",
        "                            w1 -= learning_rate * np.dot(X[j:j+batch_size].T, d1)\n",
        "                            b1 -= learning_rate * np.sum(d1, axis=0)\n",
        "                           # Evaluate the model with the best hyperparameter combination\n",
        "                            z1 = np.dot(X, w1) + b1\n",
        "                            a1 = tanh(z1)\n",
        "                            z2 = np.dot(a1, w2) + b2\n",
        "                            a2 = tanh(z2)\n",
        "                            z3 = np.dot(a2, w3) + b3\n",
        "                            y_hat = sigmoid(z3)\n",
        "                            accuracy = np.mean((y_hat > 0.5) == y)\n",
        "                            if accuracy > best_accuracy:\n",
        "                             best_accuracy = accuracy\n",
        "                             best_hyperparameters = {\n",
        "                             'batch_size': batch_size,\n",
        "                             'epoch': epoch,\n",
        "                             'learning_rate': learning_rate,\n",
        "                             'hidden_layer1_neurons': h1_neurons,\n",
        "                             'hidden_layer2_neurons': h2_neurons\n",
        "                                                    }\n",
        "\n",
        "#Print the best hyperparameters and accuracy\n",
        "print(\"Best hyperparameters: \", best_hyperparameters)\n",
        "print(\"Best accuracy: \", best_accuracy)\n",
        "\n",
        "\n",
        "#This code will train and evaluate the model with different hyperparameter combinations and print the best hyperparameters and accuracy achieved. You can modify the hyperparameters and their ranges as per your requirements.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sw0psk4efGBX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}